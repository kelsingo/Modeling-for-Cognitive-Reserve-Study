{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelsingo/Modeling-for-Cognitive-Reserve-Study/blob/main/Model_Implementation_Stage_1%262.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Implementation"
      ],
      "metadata": {
        "id": "LxNPKYEzZ9OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CouplingLoss():\n",
        "    def l1distance(true, pred):\n",
        "        torch.sum(torch.abs(true - pred))\n",
        "\n",
        "    def center_shift_loss(true, pred):\n",
        "        true_centered = true - torch.mean(true, dim=-1, keepdim=True)\n",
        "        pred_centered = pred - torch.mean(pred, dim=-1, keepdim=True)\n",
        "        return torch.mean((pred_centered - true_centered) ** 2)\n",
        "\n",
        "    def interval_loss(true, pred):\n",
        "        diff_true = true[:, 1:] - true[:, :-1]\n",
        "        diff_pred = pred[:, 1:] - pred[:, :-1]\n",
        "        return torch.mean((diff_pred - diff_true) ** 2)\n",
        "\n",
        "    def loss(self,\n",
        "              bold_true, bold_pred,\n",
        "              t_true, t_pred,\n",
        "              width_true, width_pred,\n",
        "              amp_true, amp_pred,\n",
        "              coupling_true, coupling_pred,\n",
        "              delay_true, delay_pred):\n",
        "\n",
        "        # Stage 1\n",
        "        LBOLD = self.l1distance(bold_true, bold_pred)\n",
        "\n",
        "        # Ltiming = L1(t_true, t_pred) + Lcenter_shift + Linterval\n",
        "        L_timing_base = self.l1distance(t_true, t_pred)\n",
        "        L_center_shift = self.center_shift_loss(t_true, t_pred)\n",
        "\n",
        "        L_interval = self.interval_loss(t_true, t_pred)\n",
        "\n",
        "        Ltiming = L_timing_base + L_center_shift + L_interval\n",
        "\n",
        "        # width and amplitude losses\n",
        "        Lwidth = self.l1distance(width_true, width_pred)\n",
        "\n",
        "        # Lamplitude uses mean amplitude per sample\n",
        "        Lamplitude = self.l1distance(torch.mean(amp_true, dim=-1),\n",
        "                             torch.mean(amp_pred, dim=-1))\n",
        "\n",
        "        Lstage1 = LBOLD + 0.3 * Ltiming + Lwidth + Lamplitude\n",
        "\n",
        "        # Stage 2\n",
        "        Lcoupling = self.l1distance(coupling_true, coupling_pred)\n",
        "        Ldelay = self.l1distance(delay_true, delay_pred)\n",
        "\n",
        "        Lstage2 = Lcoupling + Ldelay\n",
        "\n",
        "        # Stage 3\n",
        "        Lstage3 = Lstage1 + Lstage2\n",
        "\n",
        "        return {\n",
        "            'Lstage1': Lstage1,\n",
        "            'Lstage2': Lstage2,\n",
        "            'Lstage3': Lstage3,\n",
        "            'LBOLD': LBOLD,\n",
        "            'Ltiming': Ltiming,\n",
        "            'Lwidth': Lwidth,\n",
        "            'Lamplitude': Lamplitude,\n",
        "            'Lcoupling': Lcoupling,\n",
        "            'Ldelay': Ldelay\n",
        "        }"
      ],
      "metadata": {
        "id": "pjjSau5TZ0Ni"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation"
      ],
      "metadata": {
        "id": "6ftGaAYzZ6sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from mamba_ssm import Mamba\n",
        "\n",
        "class MambaModule(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.mb = Mamba(d_model=input_dim, d_state=16, d_conv=4, expand=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.mb(x)\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim=None, dropout=0.0):\n",
        "        super().__init__()\n",
        "        if hidden_dim is None:\n",
        "            hidden_dim = dim * 4\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.ffn(x)\n",
        "\n",
        "class Conditional_Mamba_Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_roi, dropout):\n",
        "        super().__init__()\n",
        "        self.linear_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.mb = MambaModule(hidden_dim)\n",
        "        self.roi_adapter_weights = nn.Parameter(torch.randn(n_roi, hidden_dim, hidden_dim))\n",
        "        self.roi_adapter_bias = nn.Parameter(torch.randn(n_roi, hidden_dim))\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, roi_ids):\n",
        "        # x: (B*N, L, Din), roi_ids: (B*N)\n",
        "        h_proj = self.linear_proj(x)\n",
        "        h_base = self.mb(h_proj)\n",
        "        w = self.roi_adapter_weights[roi_ids]\n",
        "        b = self.roi_adapter_bias[roi_ids]\n",
        "        h_adapt = torch.bmm(h_base, w) + b.unsqueeze(1)\n",
        "        h_out = h_base + h_adapt\n",
        "        y = self.drop(self.norm(h_out))\n",
        "        return y\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, dim, heads=8, dropout=0.0, batch_first=True):\n",
        "        super().__init__()\n",
        "        self.norm_q = nn.LayerNorm(dim)\n",
        "        self.norm_kv = nn.LayerNorm(dim)\n",
        "        self.attn  = nn.MultiheadAttention(dim, heads, dropout=dropout, batch_first=batch_first)\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.ffn   = FeedForward(dim, dropout=dropout)\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, q, kv, attn_mask=None, key_padding_mask=None, need_weights=False):\n",
        "        q_norm = self.norm_q(q)\n",
        "        kv_norm = self.norm_kv(kv)\n",
        "        ctx, attn_w = self.attn(\n",
        "            query=q_norm, key=kv_norm, value=kv_norm,\n",
        "            attn_mask=attn_mask, key_padding_mask=key_padding_mask,\n",
        "            need_weights=need_weights\n",
        "        )\n",
        "        x = q + self.drop1(ctx)\n",
        "        x = x + self.drop2(self.ffn(self.norm2(x)))\n",
        "        return (x, attn_w) if need_weights else x"
      ],
      "metadata": {
        "id": "fXkFjcXNcgJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HRF_Generator(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_roi, dropout):\n",
        "        super().__init__()\n",
        "        self.Conditional_mb = Conditional_Mamba_Encoder(input_dim, hidden_dim, n_roi, dropout)\n",
        "        self.linear_proj = nn.Linear(hidden_dim, 6)\n",
        "\n",
        "    def calculate_hrf(self, params, t):\n",
        "        t = t.unsqueeze(0) + 1e-9  # (1, L)\n",
        "\n",
        "        # Use softplus to ensure time/shape params are positive\n",
        "        tp = F.softplus(params[:, 0].unsqueeze(1)) + 1e-9  # Scale 1 (peak time)\n",
        "        tu = F.softplus(params[:, 1].unsqueeze(1)) + 1e-9  # Scale 2 (undershoot time)\n",
        "        A  = params[:, 2].unsqueeze(1)                   # Amplitude 1 (peak)\n",
        "        au = params[:, 3].unsqueeze(1)                   # Amplitude 2 (undershoot ratio)\n",
        "        a1 = F.softplus(params[:, 4].unsqueeze(1)) + 1   # Shape 1\n",
        "        a2 = F.softplus(params[:, 5].unsqueeze(1)) + 1   # Shape 2\n",
        "\n",
        "        # Term 1 (Peak)\n",
        "        term1 = A * torch.pow(t / tp, a1 - 1) * torch.exp(-t / tp)\n",
        "\n",
        "        # Term 2 (Undershoot)\n",
        "        term2 = au * torch.pow(t / tu, a2 - 1) * torch.exp(-t / tu)\n",
        "\n",
        "        # Final HRF\n",
        "        hrf = term1 - term2\n",
        "        return hrf # (B*N, L)\n",
        "\n",
        "    def forward(self, x, roi_ids):\n",
        "        # x: (B*N, L, Din), roi_ids: (B*N)\n",
        "\n",
        "        # 1: Get features from Conditional Mamba\n",
        "        features = self.Conditional_mb(x, roi_ids)\n",
        "\n",
        "        # 2: Project features to parameter space\n",
        "        # (B*N, L, Dh) -> (B*N, L, 6)\n",
        "        param_features = self.linear_proj(features)\n",
        "\n",
        "        # 3: Pool features over time to get 6 params per signal\n",
        "        # (B*N, L, 6) -> (B*N, 6)\n",
        "        hrf_params = torch.mean(param_features, dim=1)\n",
        "\n",
        "        # 4: Create the time vector\n",
        "        L = x.shape[1]\n",
        "        time_vector = torch.arange(L, device=x.device, dtype=x.dtype)\n",
        "\n",
        "        # 5: Generate the HRF time series using the parameters\n",
        "        # (B*N, 6) -> (B*N, L)\n",
        "        hrf_timeseries = self.calculate_hrf(hrf_params, time_vector)\n",
        "\n",
        "        # 6: Reshape to (B*N, L, 1) to match diagram\n",
        "        return hrf_timeseries.unsqueeze(-1)"
      ],
      "metadata": {
        "id": "rF6LG7AUczVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BOLD_Deconvolver(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_roi, num_peaks, num_params, dropout):\n",
        "        super().__init__()\n",
        "        self.conditional_mamba = Conditional_Mamba_Encoder(input_dim, hidden_dim, n_roi, dropout)\n",
        "        self.learnable_query = nn.Parameter(torch.randn(1, num_peaks, hidden_dim))\n",
        "        self.cross_attention = CrossAttention(dim=hidden_dim, heads=8, dropout=dropout)\n",
        "        self.param_head = nn.Linear(hidden_dim, num_params)\n",
        "\n",
        "    def calculate_lfp_signal(self, params, t):\n",
        "        t = t.unsqueeze(0) + 1e-9 # (1, L)\n",
        "\n",
        "        # Use softplus to ensure tau and n are positive\n",
        "        A = params[:, 0].unsqueeze(1)                   # Amplitude\n",
        "        tau = F.softplus(params[:, 1].unsqueeze(1)) + 1e-9 # Time-scale\n",
        "        n = F.softplus(params[:, 2].unsqueeze(1)) + 1    # Shape (n > 1)\n",
        "\n",
        "        # Gamma function: A * (t/tau)^(n-1) * exp(-t/tau)\n",
        "        log_base = torch.log(t / tau)\n",
        "        log_term1 = (n - 1) * log_base\n",
        "        term2 = -t / tau\n",
        "        signal = A * torch.exp(log_term1 + term2)\n",
        "\n",
        "        return signal # (B*N, L)\n",
        "\n",
        "    def forward(self, x, roi_ids):\n",
        "        # x: (B*N, L, Din), roi_ids: (B*N)\n",
        "\n",
        "        # 1: Conditional Mamba\n",
        "        # (B*N, L, 1) -> (B*N, L, H)\n",
        "        features = self.conditional_mamba(x, roi_ids)\n",
        "\n",
        "        # 2: Cross Attention\n",
        "        query = self.learnable_query.expand(x.shape[0], -1, -1)\n",
        "        # (B*N, num_peaks, H)\n",
        "        context_vector = self.cross_attention(q=query, kv=features)\n",
        "\n",
        "        # 3: Linear (to LFP-like parameters)\n",
        "        pooled_context = torch.mean(context_vector, dim=1) # (B*N, H)\n",
        "        lfp_params = self.param_head(pooled_context) # (B*N, 3)\n",
        "\n",
        "        # 4: Deconv BOLD (Generate time series)\n",
        "        L = x.shape[1]\n",
        "        time_vector = torch.arange(L, device=x.device, dtype=x.dtype)\n",
        "\n",
        "        # (B*N, 3) -> (B*N, L)\n",
        "        deconv_signal = self.calculate_lfp_signal(lfp_params, time_vector)\n",
        "\n",
        "        # 5: Reshape to match diagram output: (B*N, L, 1)\n",
        "        return deconv_signal.unsqueeze(-1)"
      ],
      "metadata": {
        "id": "_O46l3dbc39M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Stage1Model(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_roi, dropout,\n",
        "                 num_peaks=5, lfp_params=3):\n",
        "        super().__init__()\n",
        "        self.hrf_generator = HRF_Generator(input_dim, hidden_dim, n_roi, dropout)\n",
        "        self.bold_deconvolver = BOLD_Deconvolver(input_dim, hidden_dim, n_roi, num_peaks, lfp_params, dropout)\n",
        "\n",
        "    def forward(self, x, roi_ids):\n",
        "        # 0: Get dimensions\n",
        "        B, N, L, Din = x.shape\n",
        "\n",
        "        # 1: Reshape BOLD\n",
        "        # (B, N, L, 1) -> (B*N, L, 1)\n",
        "        x_flat = x.reshape(B*N, L, Din)\n",
        "\n",
        "        # Also flatten roi_ids: (B, N) -> (B*N)\n",
        "        ids_flat = roi_ids.reshape(B*N)\n",
        "\n",
        "        # 2: Pass through both branches\n",
        "        # (B*N, L, 1)\n",
        "        hrf_signal = self.hrf_generator(x_flat, ids_flat)\n",
        "\n",
        "        # (B*N, L, 1)\n",
        "        deconv_signal = self.bold_deconvolver(x_flat, ids_flat)\n",
        "\n",
        "        # 3: Convolve deconv BOLD (neural) with HRF\n",
        "        # Both inputs must be (B*N, 1, L) for conv1d\n",
        "        deconv_permuted = deconv_signal.permute(0, 2, 1) # (B*N, 1, L)\n",
        "        hrf_permuted = hrf_signal.permute(0, 2, 1)     # (B*N, 1, L)\n",
        "\n",
        "        # Use padding='same' to keep length L\n",
        "        # Use groups=B*N for depthwise conv (each signal convolved with its own HRF)\n",
        "        reconstructed_flat = F.conv1d(\n",
        "            deconv_permuted,\n",
        "            hrf_permuted,\n",
        "            padding='same',\n",
        "            groups=B*N\n",
        "        ) # Output shape: (B*N, 1, L)\n",
        "\n",
        "        # 4: Reshape back to (B, N, L, 1)\n",
        "        reconstructed_bold = reconstructed_flat.permute(0, 2, 1).reshape(B, N, L, 1)\n",
        "\n",
        "        return reconstructed_bold"
      ],
      "metadata": {
        "id": "gXyQDgiWc69i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalityMapper(nn.Module):\n",
        "    def __init__(self, hidden_dim, mlp_hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # The input to the MLPs will be 2*H (from concatenation)\n",
        "        mlp_input_dim = 2 * hidden_dim\n",
        "\n",
        "        # MLP for Coupling Strengths\n",
        "        self.mlp_strength = nn.Sequential(\n",
        "            nn.Linear(mlp_input_dim, mlp_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mlp_hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "        # MLP for Delay Timings\n",
        "        self.mlp_delay = nn.Sequential(\n",
        "            nn.Linear(mlp_input_dim, mlp_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mlp_hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, features):\n",
        "        # 1. Mean pool over time (L)\n",
        "        # (B, N, L, H) -> (B, N, H)\n",
        "        node_features = torch.mean(features, dim=2)\n",
        "\n",
        "        # 2. Expand & Concat to create pairwise features\n",
        "        B, N, H = node_features.shape\n",
        "\n",
        "        # (B, N, H) -> (B, N, 1, H) -> (B, N, N, H)\n",
        "        feat_i = node_features.unsqueeze(2).expand(-1, -1, N, -1)\n",
        "\n",
        "        # (B, N, H) -> (B, 1, N, H) -> (B, N, N, H)\n",
        "        feat_j = node_features.unsqueeze(1).expand(-1, N, -1, -1)\n",
        "\n",
        "        # (B, N, N, 2*H)\n",
        "        pairwise_features = torch.cat([feat_i, feat_j], dim=-1)\n",
        "\n",
        "        # 3. Pass through MLPs\n",
        "        # (B, N, N, 2*H) -> (B, N, N, 1) -> (B, N, N)\n",
        "        coupling_strengths = self.mlp_strength(pairwise_features).squeeze(-1)\n",
        "\n",
        "        # (B, N, N, 2*H) -> (B, N, N, 1) -> (B, N, N)\n",
        "        delay_timings = self.mlp_delay(pairwise_features).squeeze(-1)\n",
        "\n",
        "        return coupling_strengths, delay_timings"
      ],
      "metadata": {
        "id": "3l3Ctn9BjLRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Stage2Model(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_roi, dropout, mlp_hidden_dim=None):\n",
        "        super().__init__()\n",
        "\n",
        "        if mlp_hidden_dim is None:\n",
        "            mlp_hidden_dim = hidden_dim\n",
        "\n",
        "        self.n_roi = n_roi\n",
        "        self.conditional_mamba = Conditional_Mamba_Encoder(input_dim, hidden_dim, n_roi, dropout)\n",
        "        self.causality_mapper = CausalityMapper(hidden_dim, mlp_hidden_dim)\n",
        "\n",
        "    def forward(self, deconv_bold_flat, roi_ids_flat):\n",
        "        # 1. Pass through Conditional Mamba\n",
        "        # (B*N, L, 1) -> (B*N, L, H)\n",
        "        features_flat = self.conditional_mamba(deconv_bold_flat, roi_ids_flat)\n",
        "\n",
        "        # 2. Reshape features for Causality Mapper\n",
        "        # (B*N, L, H) -> (B, N, L, H)\n",
        "        BN, L, H = features_flat.shape\n",
        "        B = BN // self.n_roi\n",
        "        N = self.n_roi\n",
        "        features = features_flat.reshape(B, N, L, H)\n",
        "\n",
        "        # 3. Pass through Causality Mapper\n",
        "        # (B, N, L, H) -> (B, N, N), (B, N, N)\n",
        "        coupling_strengths, delay_timings = self.causality_mapper(features)\n",
        "\n",
        "        return coupling_strengths, delay_timings"
      ],
      "metadata": {
        "id": "Vtj609EWjVs5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}